<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>URL Click Analysis</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>




</head>

<body>
<h1>URL Click Analysis</h1>

<p>This is an R Markdown document. Markdown is a simple formatting syntax for authoring web pages where you can embed R codes. </p>

<p>The <a href="https://s3.amazonaws.com/coursera_intro_data_science_project/coursera.sanitized.csv">source data</a>. Special thanks to Nandita for coming up with an idea for processing URL and Refer URL variables.</p>

<h2>Data inspection and cleanup</h2>

<h3>load raw data</h3>

<pre><code class="r"># raw &lt;- read.csv(&#39;coursera.sanitized.csv&#39;) sapply(raw[1, ], class)
</code></pre>

<h3>click:</h3>

<p>An integer representing whether or not a click occurred - this is the outcome we want to predict</p>

<pre><code class="r"># table(raw$click) just those actually got any clicks clicked &lt;-
# raw[raw$click==1,]
</code></pre>

<h3>datehour:</h3>

<p>A string describing the day and hour when the ad was served</p>

<pre><code class="r"># head(raw$datehour) sum(is.na(raw$datehour)) convert string to datetime
# object pdata &lt;- raw datehour &lt;- strptime(raw$datehour, &#39;%Y-%m-%d
# %H:%M:%S&#39;) pdata$wday &lt;- datehour$wday pdata$hour &lt;- datehour$hour
# pdata$datehour &lt;- datehour
</code></pre>

<h3>v_id:</h3>

<p>An integer representing a channel in which a viewer has been served through. </p>

<pre><code class="r"># table(pdata$v_id) just those actually got any clicks table(clicked$v_id)
# check missing values sum(is.na(pdata$v_id))
</code></pre>

<h3>b_id:</h3>

<p>An integer representing a class of user based on their interests</p>

<pre><code class="r"># length(unique(pdata$b_id)) just those actually got any clicks
# length(unique(clicked$b_id)) check missing values sum(is.na(pdata$b_id))
# inspect data head(pdata$b_id) check the number of NULL values
# sum(pdata$b_id==&#39;\\N&#39;) rename &#39;\\N&#39; to 0 and convert the factor into
# integer levels(pdata$b_id)[levels(pdata$b_id) == &#39;\\N&#39;] &lt;- &#39;0&#39;
# pdata$b_id &lt;- as.numeric(as.character(pdata$b_id))
</code></pre>

<h3>t_id:</h3>

<p>An integer identifying a specific ad</p>

<pre><code class="r"># length(unique(pdata$t_id)) just those actually got any clicks
# length(unique(clicked$t_id)) check missing values sum(is.na(pdata$t_id))
</code></pre>

<h3>seller:</h3>

<p>An integer representing the seller providing the wholesaler with the impression</p>

<pre><code class="r"># length(unique(pdata$seller)) just those actually got any clicks
# length(unique(clicked$seller)) check missing values
# sum(is.na(pdata$seller)) check the value range
# min(pdata$seller[!is.na(pdata$seller)])
# max(pdata$seller[!is.na(pdata$seller)])
# pdata$seller[is.na(pdata$seller)] &lt;- 3000 sum(is.na(pdata$seller))
</code></pre>

<h3>country:</h3>

<p>A string representing the clicker&#39;s country of origin</p>

<pre><code class="r"># table(pdata$country) just those actually got any clicks
# table(clicked$country) check NULL values levels(pdata$country)
# levels(pdata$country)[levels(pdata$country) == &#39;&#39;] &lt;- &#39;00&#39;
# levels(pdata$country)
</code></pre>

<h3>state:</h3>

<p>A string representing the clicker&#39;s state of origin</p>

<pre><code class="r"># length(unique(pdata$state)) just those actually got any clicks
# length(unique(clicked$state)) check NULL values levels(pdata$state)
# levels(pdata$state)[levels(pdata$state) == &#39;&#39;] &lt;- &#39;00&#39;
# levels(pdata$state)
</code></pre>

<h3>url:</h3>

<p>An encrypted string representing the URL the ad was displayed on</p>

<pre><code class="r"># length(unique(pdata$url)) just those actually got any clicks
# length(unique(clicked$url)) check NULL values
# levels(pdata$url)[levels(pdata$url) == &#39;&#39;]
</code></pre>

<p>Check the frequency of urls = views. Special thanks to Nandita for coming up with this metric. </p>

<pre><code class="r"># quantile(table(pdata$url))
# barplot(sort(table(pdata$url),decreasing=TRUE), col=&#39;blue&#39;)
# barplot(sort(table(clicked$url),decreasing=TRUE), col=&#39;blue&#39;) views &lt;-
# as.data.frame(table(pdata$url)) names(views) &lt;- c(&#39;url&#39;, &#39;views&#39;)
</code></pre>

<p>Check the number of traffic sources - this represents the popularity of a given URL similar to PageRank algorithm. This is also based on Nandita&#39;s idea.</p>

<pre><code class="r">sourceCount &lt;- function(page_url) {
    ref &lt;- pdata$refer_url[pdata$url == page_url]
    return(length(unique(ref)))
}

# exetime &lt;- system.time(views$srcs &lt;- sapply(views[,1], sourceCount))
# exetime[3]/60
</code></pre>

<p>Add the views and source counts to the data</p>

<pre><code class="r"># pdata &lt;- merge(pdata,views,all=TRUE)
</code></pre>

<h3>refer_url:</h3>

<p>An encrypted string representing the referrer URL</p>

<pre><code class="r"># length(unique(pdata$refer_url)) just those actually got any clicks
# length(unique(clicked$refer_url)) check NULL values
# levels(pdata$refer_url)[levels(pdata$refer_url) == &#39;&#39;]
</code></pre>

<p>Check the frequency of refer_urls</p>

<pre><code class="r"># quantile(table(pdata$refer_url))
# barplot(sort(table(pdata$refer_url),decreasing=TRUE), col=&#39;blue&#39;)
# barplot(sort(table(clicked$refer_url),decreasing=TRUE), col=&#39;blue&#39;)
</code></pre>

<p>Add the frequency to the data - this represents how frequently a given referrer sends traffic - the larger frequency, the more active. </p>

<pre><code class="r"># referrals &lt;- as.data.frame(table(pdata$refer_url)) names(referrals) &lt;-
# c(&#39;refer_url&#39;, &#39;referrals&#39;) pdata &lt;- merge(pdata,referrals,all=TRUE)
</code></pre>

<h3>Check the cleanup result</h3>

<pre><code class="r"># pdata &lt;- pdata[,c(&#39;datehour&#39;,&#39;wday&#39;,&#39;hour&#39;, &#39;v_id&#39;, &#39;b_id&#39;, &#39;t_id&#39;,
# &#39;seller&#39;, &#39;country&#39;, &#39;state&#39;, &#39;views&#39;, &#39;srcs&#39;, &#39;referrals&#39;, &#39;url&#39;,
# &#39;refer_url&#39;, &#39;click&#39;)] summary(pdata) head(pdata) save(pdata,
# file=&#39;processed.rda&#39;)
load(file = &quot;processed.rda&quot;)
</code></pre>

<h2>Deal with the class imbalance</h2>

<h3>Reduce the majority class by subsumpling</h3>

<p>Here we are making an assumption that we can ignore most of the cases where a click didn&#39;t occur without impeding our ability to detect the cases where it did occur.</p>

<pre><code class="r"># first check the ratio between the two classes
table(pdata$click)
</code></pre>

<pre><code>## 
##      0      1 
## 782725    217
</code></pre>

<pre><code class="r">
# drop url and refer_url variables
pdata &lt;- pdata[, !(names(pdata) %in% c(&quot;datehour&quot;, &quot;url&quot;, &quot;refer_url&quot;))]
# convert click to a factor
pdata$click &lt;- as.factor(pdata$click)

# subample the super majority class to reduce the ratio to 10:1
maj &lt;- pdata[pdata$click == 0, ]
subSampling &lt;- sample(1:dim(maj)[1], size = 217 * 10, replace = FALSE)
subSampled &lt;- rbind(pdata[pdata$click == 1, ], maj[subSampling, ])
table(subSampled$click)
</code></pre>

<pre><code>## 
##    0    1 
## 2170  217
</code></pre>

<pre><code class="r">summary(subSampled)
</code></pre>

<pre><code>##       wday           hour           v_id           b_id     
##  Min.   :2.00   Min.   : 0.0   Min.   :0.00   Min.   :   0  
##  1st Qu.:2.00   1st Qu.: 4.0   1st Qu.:1.00   1st Qu.:   0  
##  Median :3.00   Median :13.0   Median :1.00   Median :   0  
##  Mean   :3.23   Mean   :11.5   Mean   :1.13   Mean   : 136  
##  3rd Qu.:4.00   3rd Qu.:17.0   3rd Qu.:1.00   3rd Qu.:  32  
##  Max.   :6.00   Max.   :23.0   Max.   :3.00   Max.   :1539  
##                                                             
##       t_id          seller     country       state          views      
##  Min.   :9595   Min.   :   0   00:  16   AB     :1420   Min.   :    1  
##  1st Qu.:9600   1st Qu.: 459   BR:   0   MB     : 829   1st Qu.:  324  
##  Median :9601   Median :1263   CA:2368   SK     : 101   Median : 2163  
##  Mean   :9602   Mean   :1177   EG:   0   00     :  16   Mean   : 6599  
##  3rd Qu.:9606   3rd Qu.:1362   ES:   0   ON     :   8   3rd Qu.: 8143  
##  Max.   :9612   Max.   :3000   US:   3   BC     :   7   Max.   :35898  
##                                          (Other):   6                  
##       srcs         referrals     click   
##  Min.   :  1.0   Min.   :    1   0:2170  
##  1st Qu.:  2.0   1st Qu.:  853   1: 217  
##  Median :  4.0   Median : 5843           
##  Mean   : 25.4   Mean   :18781           
##  3rd Qu.:  8.0   3rd Qu.:42085           
##  Max.   :539.0   Max.   :61337           
## 
</code></pre>

<h3>Setup Cross Validation</h3>

<p>In order to test the predictive model, we will split the downsampled data into two subsets. We will also take a sampling from the original data without downsampling the majority class.</p>

<pre><code class="r"># split data into two subsets - 2/3 training set, 1/3 test set
set.seed(333)
trainSamples &lt;- sample(1:dim(subSampled)[1], size = (dim(subSampled)[1]/3 * 
    2), replace = FALSE)
train &lt;- subSampled[trainSamples, ]
test &lt;- subSampled[-trainSamples, ]
# we will also have a validation set from the original data
valSamples &lt;- sample(1:dim(pdata)[1], size = dim(pdata)[1]/50, replace = FALSE)
validation &lt;- pdata[valSamples, ]
# check the number of minority class - should be around 145:72
sum(train$click == 1)
</code></pre>

<pre><code>## [1] 140
</code></pre>

<pre><code class="r">sum(test$click == 1)
</code></pre>

<pre><code>## [1] 77
</code></pre>

<pre><code class="r">sum(validation$click == 1)
</code></pre>

<pre><code>## [1] 4
</code></pre>

<h2>Random Forest</h2>

<p>We try to build a predictive model using a random forest, with parameters set to take 10 samples from each class per iteration to make sure we get a balanced result. </p>

<pre><code class="r">suppressPackageStartupMessages(library(randomForest))
table(train$click)
</code></pre>

<pre><code>## 
##    0    1 
## 1451  140
</code></pre>

<pre><code class="r">set.seed(1234)
rf.model1 &lt;- randomForest(click ~ ., data = train, importance = TRUE, prox = TRUE, 
    strata = train$click, sampsize = c(10, 10))
rf.model1
</code></pre>

<pre><code>## 
## Call:
##  randomForest(formula = click ~ ., data = train, importance = TRUE,      prox = TRUE, strata = train$click, sampsize = c(10, 10)) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 37.96%
## Confusion matrix:
##     0   1 class.error
## 0 918 533      0.3673
## 1  71  69      0.5071
</code></pre>

<p>The class error rate for click = 1 is 35.0% - which is not so great, but at least we are getting more than half of them right. </p>

<p>Now let&#39;s see how much accuracy we get on the test set. </p>

<pre><code class="r"># make prediction from the test set
test.pred1 &lt;- predict(rf.model1, test[, -12])
# compare it to the actual outcome
confusionMatrix &lt;- table(observed = test$click, predicted = test.pred1)
confusionMatrix
</code></pre>

<pre><code>##         predicted
## observed   0   1
##        0 434 285
##        1  28  49
</code></pre>

<pre><code class="r"># class error rate of click=1
confusionMatrix[2, 1]/sum(confusionMatrix[2, ])
</code></pre>

<pre><code>## [1] 0.3636
</code></pre>

<p>The class error rate is 29.9% - a bit better.</p>

<p>Now let&#39;s make prediction with validation set</p>

<pre><code class="r"># make prediction from the validation set
validation.pred1 &lt;- predict(rf.model1, validation[, -12])
# compare it to the actual outcome
confusionMatrix &lt;- table(observed = validation$click, predicted = validation.pred1)
confusionMatrix
</code></pre>

<pre><code>##         predicted
## observed    0    1
##        0 9886 5768
##        1    1    3
</code></pre>

<pre><code class="r"># class error rate of click=1
confusionMatrix[2, 1]/sum(confusionMatrix[2, ])
</code></pre>

<pre><code>## [1] 0.25
</code></pre>

<p>The class error rate is 25.0% - we called 3 out of 4 correctly.</p>

<pre><code class="r">result &lt;- importance(rf.model1, )[, &quot;MeanDecreaseAccuracy&quot;]
importance(rf.model1)[order(result, decreasing = TRUE), ]
</code></pre>

<pre><code>##                0       1 MeanDecreaseAccuracy MeanDecreaseGini
## views     3.2771  4.4915               4.1200        1.6590082
## referrals 3.0914  1.3381               3.4903        1.4041509
## srcs      1.3740  2.7841               1.8055        1.0471955
## b_id      1.0697  1.8514               1.4313        0.6454228
## seller    0.7796  2.8447               1.3951        1.2557797
## v_id      1.2974 -0.2263               1.3550        0.2444988
## state     1.2817 -1.3130               1.2113        0.3107043
## country   1.0010  0.0000               1.0010        0.0002727
## hour      0.9406 -0.7737               0.7402        1.4177433
## t_id      0.3015 -2.5240              -0.1075        1.0677502
## wday      0.0538 -0.9365              -0.2385        0.8120070
</code></pre>

<p>The result rank the variable&#39;s importance by how much each contribute to reduce prediction error. However, the differences are pretty small, so I am not confident that this is a robust result.</p>

<h2>Improving the model</h2>

<p>Wenjia points out that two variables that show high importance, seller and b_id, happen to contain a lot of NULL values. These NULL values may be artificially raising the apparent importance of those variables.</p>

<h3>Seller variable</h3>

<p>Let&#39;s examine &ldquo;seller&rdquo; variable.</p>

<pre><code class="r"># 94129 null values in &#39;seller&#39; variable were re-coded with 3000
table(pdata$seller[pdata$seller == 3000], pdata$v_id[pdata$seller == 3000])
</code></pre>

<pre><code>##       
##            3
##   3000 94129
</code></pre>

<pre><code class="r">length(pdata$v_id[pdata$v_id == 3])
</code></pre>

<pre><code>## [1] 94129
</code></pre>

<p>It looks none of the v_id==3 conains valid seller id. 
So what happens if we remove v_id==3?</p>

<pre><code class="r"># New random forest without v_id==3
rf.model2 &lt;- randomForest(click ~ ., data = train[train$v_id != 3, ], importance = TRUE, 
    prox = TRUE, strata = train$click[train$v_id != 3], sampsize = c(10, 10))
rf.model2
</code></pre>

<pre><code>## 
## Call:
##  randomForest(formula = click ~ ., data = train[train$v_id !=      3, ], importance = TRUE, prox = TRUE, strata = train$click[train$v_id !=      3], sampsize = c(10, 10)) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 39.82%
## Confusion matrix:
##     0   1 class.error
## 0 784 505      0.3918
## 1  58  67      0.4640
</code></pre>

<pre><code class="r">result &lt;- importance(rf.model2, )[, &quot;MeanDecreaseAccuracy&quot;]
importance(rf.model2)[order(result, decreasing = TRUE), ]
</code></pre>

<pre><code>##                  0       1 MeanDecreaseAccuracy MeanDecreaseGini
## srcs       3.79019  4.6311              4.52709           1.3089
## views      2.98890  2.8276              3.58901           1.7262
## referrals  1.75569  2.4379              2.36092           1.5154
## b_id       1.54055  2.6309              2.24424           0.5096
## seller     1.44731  2.5090              1.99971           1.4115
## state      1.95871 -1.4849              1.93269           0.2739
## wday       1.40661 -1.6918              0.85456           0.7444
## v_id       0.02666  0.9979              0.17227           0.1620
## t_id       0.29105 -2.0345              0.02757           0.8111
## country    0.00000  0.0000              0.00000           0.0000
## hour      -0.07618 -1.2618             -0.36988           1.4282
</code></pre>

<p>The importance of &ldquo;seller&rdquo; variable drops significantly once the null values are removed. For this reason, we can probably ignore this variable altogether. </p>

<pre><code class="r"># New random forest without seller variable
noseller &lt;- train
noseller$seller &lt;- NULL
rf.model3 &lt;- randomForest(click ~ ., data = noseller, importance = TRUE, prox = TRUE, 
    strata = noseller$click, sampsize = c(10, 10))
rf.model3
</code></pre>

<pre><code>## 
## Call:
##  randomForest(formula = click ~ ., data = noseller, importance = TRUE,      prox = TRUE, strata = noseller$click, sampsize = c(10, 10)) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 39.85%
## Confusion matrix:
##     0   1 class.error
## 0 883 568      0.3915
## 1  66  74      0.4714
</code></pre>

<pre><code class="r">result &lt;- importance(rf.model3, )[, &quot;MeanDecreaseAccuracy&quot;]
importance(rf.model3)[order(result, decreasing = TRUE), ]
</code></pre>

<pre><code>##                0        1 MeanDecreaseAccuracy MeanDecreaseGini
## referrals 4.0099  3.84550               4.9054         1.626035
## views     2.8819  3.09193               3.5536         1.892680
## srcs      2.9171  0.93647               3.1836         1.547856
## v_id      1.3760 -1.29107               1.2738         0.350930
## state     1.1976 -2.69347               0.9432         0.301558
## wday      0.6662 -0.05231               0.6020         0.825901
## b_id      0.2783  1.49371               0.5828         0.688996
## t_id      0.5038 -1.80794               0.2509         1.049953
## country   0.0000  0.00000               0.0000         0.002945
## hour      0.4273 -2.21424              -0.1837         1.568812
</code></pre>

<h3>b_id variable</h3>

<p>Let&#39;s now examine &ldquo;b_id&rdquo; variable. 546712 values &ldquo;//N&rdquo; variable were re-coded with 0.</p>

<pre><code class="r"># how many clicks does that class contain?
table(pdata$click[pdata$b_id == 0])
</code></pre>

<pre><code>## 
##      0      1 
## 546580    132
</code></pre>

<pre><code class="r"># how many clicks do all other classes contain?
table(pdata$click[pdata$b_id != 0])
</code></pre>

<pre><code>## 
##      0      1 
## 236145     85
</code></pre>

<p>It turned out Null value is a majority class for this variable. So what happens if we remove it?</p>

<pre><code class="r"># New random forest without null values in b_id
nonulls &lt;- noseller[noseller$b_id != 0, ]
rf.model4 &lt;- randomForest(click ~ ., data = nonulls, importance = TRUE, prox = TRUE, 
    strata = nonulls$click, sampsize = c(10, 10))
rf.model4
</code></pre>

<pre><code>## 
## Call:
##  randomForest(formula = click ~ ., data = nonulls, importance = TRUE,      prox = TRUE, strata = nonulls$click, sampsize = c(10, 10)) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 40.88%
## Confusion matrix:
##     0   1 class.error
## 0 262 167      0.3893
## 1  28  20      0.5833
</code></pre>

<pre><code class="r">result &lt;- importance(rf.model4, )[, &quot;MeanDecreaseAccuracy&quot;]
importance(rf.model4)[order(result, decreasing = TRUE), ]
</code></pre>

<pre><code>##                 0       1 MeanDecreaseAccuracy MeanDecreaseGini
## b_id       2.8195  1.2521              2.99471         1.715363
## srcs       1.6089  3.6262              2.34689         1.204936
## hour       1.3956  1.0054              1.56410         1.349173
## wday       0.3277  0.8371              0.54904         0.753447
## referrals -0.7971  3.5902              0.05585         1.498934
## country   -0.4473  0.0000             -0.44730         0.004333
## t_id      -0.2942 -1.1810             -0.55761         1.079696
## v_id      -0.2082 -2.1696             -0.63077         0.422890
## views     -0.8187  1.2141             -0.63860         1.547472
## state     -1.3208 -1.9639             -1.69868         0.375755
</code></pre>

<p>b_id still remains high, and our class error rate worsened noticeably. So it is probably not good idea to remove the records with null values. We should keep those records, but we shouldn&#39;t use this variable because of the class imbalance. </p>

<pre><code class="r"># New random forest without b_id
noBID &lt;- noseller
noBID$b_id &lt;- NULL
rf.model5 &lt;- randomForest(click ~ ., data = noBID, importance = TRUE, prox = TRUE, 
    strata = noBID$click, sampsize = c(10, 10))
rf.model5
</code></pre>

<pre><code>## 
## Call:
##  randomForest(formula = click ~ ., data = noBID, importance = TRUE,      prox = TRUE, strata = noBID$click, sampsize = c(10, 10)) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 38.4%
## Confusion matrix:
##     0   1 class.error
## 0 912 539      0.3715
## 1  72  68      0.5143
</code></pre>

<pre><code class="r">result &lt;- importance(rf.model5, )[, &quot;MeanDecreaseAccuracy&quot;]
importance(rf.model5)[order(result, decreasing = TRUE), ]
</code></pre>

<pre><code>##                  0       1 MeanDecreaseAccuracy MeanDecreaseGini
## srcs       3.68128  1.7910            4.137e+00         1.575414
## v_id       3.35143 -2.9727            3.076e+00         0.386244
## views      2.37803  3.0564            2.931e+00         2.083754
## referrals  1.29726  5.5803            2.510e+00         1.950164
## country    1.38943  0.0000            1.390e+00         0.003053
## wday      -0.17600  0.5731           -4.574e-05         0.878060
## hour       0.06016 -0.7144           -1.260e-01         1.621165
## t_id      -0.96362 -1.1880           -1.181e+00         1.121981
## state     -1.92901 -1.8976           -2.267e+00         0.269537
</code></pre>

<p>The important variables are now: views, t_id, srcs, referrals, and state. This seems to make more intuitive sense.</p>

<p>Now let&#39;s see how much accuracy we get on the test set. </p>

<pre><code class="r"># drop seller, b_id from the test set
test &lt;- test[, !(names(test) %in% c(&quot;seller&quot;, &quot;b_id&quot;))]
# make prediction from the test set
test.pred5 &lt;- predict(rf.model5, test[, -10])
# compare it to the actual outcome
confusionMatrix &lt;- table(observed = test$click, predicted = test.pred5)
confusionMatrix
</code></pre>

<pre><code>##         predicted
## observed   0   1
##        0 454 265
##        1  32  45
</code></pre>

<pre><code class="r"># class error rate of click=1
confusionMatrix[2, 1]/sum(confusionMatrix[2, ])
</code></pre>

<pre><code>## [1] 0.4156
</code></pre>

<p>Now let&#39;s make prediction with validation set</p>

<pre><code class="r"># drop seller, b_id from the validation set
validation &lt;- validation[, !(names(validation) %in% c(&quot;seller&quot;, &quot;b_id&quot;))]
# make prediction from the validation set
validation.pred5 &lt;- predict(rf.model5, validation[, -10])
# compare it to the actual outcome
confusionMatrix &lt;- table(observed = validation$click, predicted = validation.pred5)
confusionMatrix
</code></pre>

<pre><code>##         predicted
## observed    0    1
##        0 9920 5734
##        1    1    3
</code></pre>

<pre><code class="r"># class error rate of click=1
confusionMatrix[2, 1]/sum(confusionMatrix[2, ])
</code></pre>

<pre><code>## [1] 0.25
</code></pre>

<p>So we didn&#39;t lose our predictive power, either. </p>

</body>

</html>

